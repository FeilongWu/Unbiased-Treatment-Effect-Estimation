{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook documents the procedures to extract ventilation and vasoperessor treatment data for training. The files to be use (1) pivoted_vital.csv, (2) sepsis3.csv, (3) ICUSTAYS.csv, (4) vasopressor_durations.csv, (5) ventilation_classification.csv,  (6) ventilation_durations.csv, and (7) pivoted_lab.csv.\n",
    "\n",
    "(3) is used to extract the indices of the sepsis3 patients. In (5), only patient received mechanical ventilator is considered. The covarites&outcomes are found from (1) and the static features are from (2). Both (4) and (6) are treatments for vasoparessor and ventilation, respectively. (7) stores the labe results as covariates of the patients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 get sepsis3 cohort patient index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# only icustay_id is unique, the others have duplicates\n",
    "icu_adm_sub = {} # ICUSYATS-ADMISSION-SUBJECT\n",
    "sub_adm_icu = {} # SUBJECT-ADMISSION-ICUSYATS\n",
    "\n",
    "\n",
    "with open('./ICUSTAYS.csv', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    header = next(reader, None)\n",
    "    for row in reader:\n",
    "        sub = row[1]\n",
    "        adm = row[2]\n",
    "        icu = row[3]\n",
    "        if sub not in sub_adm_icu:\n",
    "            sub_adm_icu[sub] = {}\n",
    "        if adm not in sub_adm_icu[sub]:\n",
    "            sub_adm_icu[sub][adm] = []\n",
    "        if icu not in sub_adm_icu[sub][adm]:\n",
    "            sub_adm_icu[sub][adm].append(icu)\n",
    "        icu_adm_sub[icu] = {adm:sub}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'118037': ['278444', '236754']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_adm_icu['7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12612\n",
      "6742\n",
      "5010\n",
      "11307\n",
      "3711\n"
     ]
    }
   ],
   "source": [
    "angus = [] #31\n",
    "martin = [] # 32\n",
    "nqf = [] # 36\n",
    "cdc = [] # 37\n",
    "explicit = [] # 33, 34, 35\n",
    "with open('./sepsis3.csv', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    header = next(reader, None)\n",
    "    for row in reader:\n",
    "        p = icu_adm_sub[row[0]][row[1]]\n",
    "        if row[32] == '1':\n",
    "            martin.append(p)\n",
    "        if row[31] == '1':\n",
    "            angus.append(p)\n",
    "        if row[36] == '1':\n",
    "            nqf.append(p)\n",
    "        if row[37] == '1':\n",
    "            cdc.append(p)\n",
    "        if '1' in [row[33] ,  row[34]  ,row[35]]:\n",
    "            explicit.append(p)\n",
    "print(len(set(angus)))\n",
    "print(len(set(martin)))\n",
    "print(len(set(nqf)))\n",
    "print(len(set(cdc)))\n",
    "print(len(set(explicit)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 get cohort static features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nx['93535'] = {'age': 1,\\n 'sex': 2,\\n 'race': 1,\\n 'metastatic_cancer': 2,\\n 'diabetes': 2,\\n 'weight': {('200011', '121562'): 101.4},\\n 'bmi': {('200011', '121562'): ''},\\n 'height': ''}\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "icustay_id = 0\n",
    "hadm_id = 1\n",
    "admission time = 3\n",
    "age = 13\n",
    "gender = 14\n",
    "ethinity = 16\n",
    "metastatic_cancer = 21\n",
    "diabetes = 22\n",
    "height = 23\n",
    "weight = 24\n",
    "bmi = 25\n",
    "sepsis_cdc = 37\n",
    "\n",
    "Male = 1, Female = 2\n",
    "\n",
    "WHITE = 1\n",
    "BLACK = 2\n",
    "HISPANIC = 3\n",
    "ASIAN = 4\n",
    "OTHER = 5\n",
    "\n",
    "\n",
    "use cdc definition of sepsis to select patients (total = 11307)\n",
    "'''\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "X_id = []\n",
    "x = {}\n",
    "weight_sex = []\n",
    "weight_sex_h = []\n",
    "\n",
    "with open('./sepsis3.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    header = next(reader, None)\n",
    "    for row in reader:\n",
    "        if row[37] == '1': # select cohort by cdc definition\n",
    "            icustay = row[0]\n",
    "            hadm = row[1]\n",
    "            sub = icu_adm_sub[icustay][hadm]\n",
    "            if sub not in x:\n",
    "                x[sub] = {}\n",
    "            x[sub]['age'] = float(row[13])\n",
    "            gender = 1 if row[14] == 'M' else 2\n",
    "            x[sub]['sex'] = gender\n",
    "            race = row[16]\n",
    "            if 'WHITE' in race:\n",
    "                ethinity = 1\n",
    "            elif 'BLACK' in race:\n",
    "                ethinity = 2\n",
    "            elif 'HISPANIC' in race:\n",
    "                ethinity = 3\n",
    "            elif 'ASIAN' in race:\n",
    "                ethinity = 4\n",
    "            else:\n",
    "                ethinity = 5\n",
    "            x[sub]['race'] = ethinity\n",
    "            x[sub]['metastatic_cancer'] = 1 if row[21] == '1' else 2\n",
    "            x[sub]['diabetes'] = 1 if row[22] == '1' else 2\n",
    "            if 'weight' not in x[sub]:\n",
    "                x[sub]['weight'] = {}\n",
    "            if 'bmi' not in x[sub]:\n",
    "                x[sub]['bmi'] = {}\n",
    "            if 'height' not in x[sub]:\n",
    "                h = row[23]\n",
    "                if h == '':\n",
    "                    x[sub]['height'] = ''\n",
    "                else:\n",
    "                    x[sub]['height'] = float(h)\n",
    "            if x[sub]['height'] == '' and row[23] != '':\n",
    "                x[sub]['height'] = float(row[23])\n",
    "            w = '' if row[24] == '' else float(row[24])\n",
    "            bmi = '' if row[25] == '' else float(row[25])\n",
    "            if w != '':\n",
    "                weight_sex.append((w, gender))\n",
    "                if row[23] != '':\n",
    "                    weight_sex_h.append((w, gender, float(row[23])))\n",
    "            \n",
    "            index = str((icustay, hadm))\n",
    "            x[sub]['weight'][index] = w\n",
    "            x[sub]['bmi'][index] = bmi\n",
    "        \n",
    "\n",
    "# data cleaning\n",
    "mean_w = 0\n",
    "for i in weight_sex:\n",
    "    mean_w += i[0]\n",
    "mean_w = mean_w / len(weight_sex)\n",
    "\n",
    "# train linear regression model height = a*weight + b*gender + c\n",
    "h = []\n",
    "w_s = []\n",
    "for i in weight_sex_h:\n",
    "    h.append(i[2])\n",
    "    w_s.append([i[0],i[1]])\n",
    "\n",
    "reg = LinearRegression().fit(np.array(w_s), np.array(h))\n",
    "\n",
    "# impute weight\n",
    "for i in x:\n",
    "    weight = x[i]['weight']\n",
    "    values = list(weight.values())\n",
    "    impute_w = ''\n",
    "    for j in values:\n",
    "        if j != '':\n",
    "            impute_w = j\n",
    "            break\n",
    "    for j in weight:\n",
    "        if weight[j] == '':\n",
    "            x[i]['weight'][j] = impute_w if impute_w != '' else mean_w\n",
    "# impute height and bmi\n",
    "for i in x:\n",
    "    if x[i]['height'] == '':\n",
    "        weights = list(x[i]['weight'].values())\n",
    "        avg_w = sum(weights) / len(weights)\n",
    "        sex = x[i]['sex']\n",
    "        x[i]['height'] = reg.predict(np.array([[avg_w, sex]])).tolist()[0]\n",
    "for i in x:\n",
    "    for j in x[i]['bmi']:\n",
    "        if x[i]['bmi'][j] == '':\n",
    "            w = x[i]['weight'][j]\n",
    "            x[i]['bmi'][j] = w / (x[i]['height']/100)**2\n",
    "        \n",
    "# save to JSON\n",
    "f = open('./static_features.json', 'w')\n",
    "json.dump(x, f)\n",
    "f.close()\n",
    "\n",
    "'''\n",
    "x['93535'] = {'age': 1,\n",
    " 'sex': 2,\n",
    " 'race': 1,\n",
    " 'metastatic_cancer': 2,\n",
    " 'diabetes': 2,\n",
    " 'weight': {('200011', '121562'): 101.4},\n",
    " 'bmi': {('200011', '121562'): ''},\n",
    " 'height': ''}\n",
    "'''\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seelct cohort from (1) and (7) and impute the mixing values. Output the derived tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def check_none(row):\n",
    "    # row: a np.array containing elements. A none value = ''\n",
    "    # returns [is_none, idx, idx1] where is_none = 1 if there exists a none otherwise 0\n",
    "    # idx is a np.array of indexs of the none values\n",
    "    # idx1 is a np.array of indexs of the non-none values\n",
    "    \n",
    "    is_none = 0\n",
    "    idx,idx1 = [], []\n",
    "    for i,j in enumerate(row):\n",
    "        if j == '':\n",
    "            is_none = 1\n",
    "            idx.append(i)\n",
    "        else:\n",
    "            idx1.append(i)\n",
    "    return [is_none, np.array(idx), np.array(idx1)]\n",
    "\n",
    "def impute_table(table):\n",
    "    # table: a np.array that contains data and the first conlumn is time index\n",
    "    # output the table as a list of lists and perform inputation using nearest neighbor\n",
    "    \n",
    "    attr_len = len(table[0])\n",
    "    time1 = table[:, 0]\n",
    "    time = []\n",
    "    for i in time1:\n",
    "        time.append(datetime.strptime(i, '%Y-%m-%d %H:%M:%S'))\n",
    "    for i in range(1, attr_len):\n",
    "        is_none, none_idx, valid = check_none(table[:, i])\n",
    "        while is_none == 1:\n",
    "            for j in none_idx:\n",
    "                dif = abs(valid - j)\n",
    "                neigh = []\n",
    "                for k, ij in enumerate(dif):\n",
    "                    if ij == 1:\n",
    "                        neigh.append(valid[k])\n",
    "                if len(neigh) == 1:\n",
    "                    table[:, i][j] = table[:, i][neigh[0]]\n",
    "                elif len(neigh) == 2:\n",
    "                    refer1_t = time[neigh[0]]\n",
    "                    refer2_t = time[neigh[1]]\n",
    "                    none_t = time[j]\n",
    "                    nearest = neigh[0] if none_t - refer1_t < refer2_t - none_t else neigh[1]\n",
    "                    table[:, i][j] = table[:, i][nearest]\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            is_none, none_idx, valid = check_none(table[:, i])\n",
    "    return table.tolist()\n",
    "\n",
    "def no_data(table):\n",
    "    # table: a np.array that contains data and the first conlumn is time index\n",
    "    # return 1 if at least on column has only '' otherwise 0\n",
    "    \n",
    "    attr_len = len(table[0])\n",
    "    for i in range(1, attr_len):\n",
    "        col = table[:, i]\n",
    "        if all(col==''):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def reformat(table):\n",
    "    # table = {icu:[[t1,...]]}\n",
    "    # output = {icu:{t1:[], t2:[],...}}\n",
    "    for i in table:\n",
    "        t = table[i]\n",
    "        temp = {}\n",
    "        for j in t:\n",
    "            temp[j[0]] = j[1:]\n",
    "        table[i] = temp\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: 100\n",
      "Table: 200\n",
      "Table: 300\n",
      "Table: 400\n",
      "Table: 500\n",
      "Table: 600\n",
      "Table: 700\n",
      "Table: 800\n",
      "Table: 900\n",
      "Table: 1000\n",
      "Table: 1100\n",
      "Table: 1200\n",
      "Table: 1300\n",
      "Table: 1400\n",
      "Table: 1500\n",
      "Table: 1600\n",
      "Table: 1700\n",
      "Table: 1800\n",
      "Table: 1900\n",
      "Table: 2000\n",
      "Table: 2100\n",
      "Table: 2200\n",
      "Table: 2300\n",
      "Table: 2400\n",
      "Table: 2500\n",
      "Table: 2600\n",
      "Table: 2700\n",
      "Table: 2800\n",
      "Table: 2900\n",
      "Table: 3000\n",
      "Table: 3100\n",
      "Table: 3200\n",
      "Table: 3300\n",
      "Table: 3400\n",
      "Table: 3500\n",
      "Table: 3600\n",
      "Table: 3700\n",
      "Table: 3800\n",
      "Table: 3900\n",
      "Table: 4000\n",
      "Table: 4100\n",
      "Table: 4200\n",
      "Table: 4300\n",
      "Table: 4400\n",
      "Table: 4500\n",
      "Table: 4600\n",
      "Table: 4700\n",
      "Table: 4800\n",
      "Table: 4900\n",
      "Table: 5000\n",
      "Table: 5100\n",
      "Table: 5200\n",
      "Table: 5300\n",
      "Table: 5400\n",
      "Table: 5500\n",
      "Table: 5600\n",
      "Table: 5700\n",
      "Table: 5800\n",
      "Table: 5900\n",
      "Table: 6000\n",
      "Table: 6100\n",
      "Table: 6200\n",
      "Table: 6300\n",
      "Table: 6400\n",
      "Table: 6500\n",
      "Table: 6600\n",
      "Table: 6700\n",
      "Table: 6800\n",
      "Table: 6900\n",
      "Table: 7000\n",
      "Table: 7100\n",
      "Table: 7200\n",
      "Table: 7300\n",
      "Table: 7400\n",
      "Table: 7500\n",
      "Table: 7600\n",
      "Table: 7700\n",
      "Table: 7800\n",
      "Table: 7900\n",
      "Table: 8000\n",
      "Table: 8100\n",
      "Table: 8200\n",
      "Table: 8300\n",
      "Table: 8400\n",
      "Table: 8500\n",
      "Table: 8600\n",
      "Table: 8700\n",
      "Table: 8800\n",
      "Table: 8900\n",
      "Table: 9000\n",
      "Table: 9100\n",
      "Table: 9200\n",
      "Table: 9300\n",
      "Table: 9400\n",
      "Table: 9500\n",
      "Table: 9600\n",
      "Table: 9700\n",
      "Table: 9800\n",
      "Table: 9900\n",
      "Table: 10000\n",
      "Table: 10100\n",
      "Table: 10200\n",
      "Table: 10300\n",
      "Table: 10400\n",
      "Table: 10500\n",
      "Table: 10600\n",
      "Table: 10700\n",
      "Table: 10800\n",
      "Table: 10900\n",
      "Table: 11000\n",
      "Table: 11100\n",
      "Table: 11200\n",
      "Table: 11300\n",
      "Table: 11400\n",
      "Table: 11500\n",
      "Table: 11600\n",
      "Table: 11700\n",
      "Table: 11800\n",
      "Table: 11900\n",
      "Table: 12000\n",
      "Table: 12100\n",
      "Table: 12200\n",
      "Table: 12300\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "p_vital = './pivoted_vital.csv'\n",
    "\n",
    "## process pivoted_vital\n",
    "'''\n",
    "heart rate = 2\n",
    "systolic bp = 3\n",
    "dias. bp = 4\n",
    "mean bp =  5\n",
    "respiratory rate = 6\n",
    "temperature = 7\n",
    "spo2 = 8\n",
    "'''\n",
    "# get cohort icustay_id\n",
    "\n",
    "cohort_icustay = set()\n",
    "file = open('./static_features.json')\n",
    "data = json.load(file)\n",
    "for key in data:\n",
    "    w = data[key]['weight']\n",
    "    for idx in w:\n",
    "        icu = idx[2:8] # length of id = 6\n",
    "        cohort_icustay.add(icu)\n",
    "\n",
    "select_vital = {}\n",
    "\n",
    "with open(p_vital, newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    header = next(reader, None)\n",
    "    for row in reader:\n",
    "        idx = row[0]\n",
    "        if idx in cohort_icustay:\n",
    "            if idx not in select_vital:\n",
    "                select_vital[idx] = []\n",
    "            select_vital[idx].append(row[1:9])\n",
    "#\n",
    "to_be_delete = [] # keys to be deleted\n",
    "count = 0\n",
    "max_row = 1900 # typically consider first 30 hours and vital is sample every minute\n",
    "for i in select_vital:\n",
    "    table = np.array(select_vital[i][:max_row])\n",
    "    if len(table) == 1:\n",
    "        to_be_delete.append(i) # delete tables only have one time step\n",
    "        continue\n",
    "    if no_data(table):\n",
    "        to_be_delete.append(i) # delete tables that at least one attribute has no value at all time\n",
    "        continue\n",
    "    select_vital[i] = impute_table(table)\n",
    "    #print('Table: '+str(count))\n",
    "    count += 1\n",
    "    if count % 100 == 0:\n",
    "        print('Table: '+str(count))\n",
    "        \n",
    "for i in to_be_delete:\n",
    "    del select_vital[i]\n",
    "    \n",
    "#select_vital = reformat(select_vital)\n",
    "\n",
    "file = open('./selected_vital.json', 'w')\n",
    "json.dump(select_vital, file)\n",
    "################--IMPORTANT--#################\n",
    "## mnually open the file and scroll dowm to the end to see if the file format is correct.\n",
    "## Error can occur due to some unknown bug. Delete the incomplete data if neccessary and the total\n",
    "## number of tables should remain the same.\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: 100\n",
      "Table: 200\n",
      "Table: 300\n",
      "Table: 400\n",
      "Table: 500\n",
      "Table: 600\n",
      "Table: 700\n",
      "Table: 800\n",
      "Table: 900\n",
      "Table: 1000\n",
      "Table: 1100\n",
      "Table: 1200\n",
      "Table: 1300\n",
      "Table: 1400\n",
      "Table: 1500\n",
      "Table: 1600\n",
      "Table: 1700\n",
      "Table: 1800\n",
      "Table: 1900\n",
      "Table: 2000\n",
      "Table: 2100\n",
      "Table: 2200\n",
      "Table: 2300\n",
      "Table: 2400\n",
      "Table: 2500\n",
      "Table: 2600\n",
      "Table: 2700\n",
      "Table: 2800\n",
      "Table: 2900\n",
      "Table: 3000\n",
      "3042\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "p_lab = './pivoted_lab.csv'\n",
    "\n",
    "## process lab\n",
    "\n",
    "'''\n",
    "icustay_id = 0\n",
    "charttime = 3\n",
    "aniongap = 4 \n",
    "albumin = 5\n",
    "bands = 6\n",
    "bicarbonate = 7\n",
    "bilirubin = 8\n",
    "creatinine = 9\n",
    "chloride = 10\n",
    "glucose = 11\n",
    "hematocrit = 12\n",
    "hemoglobin = 13\n",
    "lactate = 14\n",
    "platelet = 15\n",
    "potassium = 16\n",
    "ptt = 17\n",
    "inr = 18\n",
    "pt = 19\n",
    "sodium = 20\n",
    "bun = 21\n",
    "wbc = 22\n",
    "'''\n",
    "cohort_icustay = set()\n",
    "file = open('./static_features.json')\n",
    "data = json.load(file)\n",
    "for key in data:\n",
    "    w = data[key]['weight']\n",
    "    for idx in w:\n",
    "        icu = idx[2:8] # length of id = 6\n",
    "        cohort_icustay.add(icu)\n",
    "\n",
    "select_lab = {}\n",
    "with open(p_lab, newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    header = next(reader, None)\n",
    "    for row in reader:\n",
    "        idx = row[0]\n",
    "        if idx in cohort_icustay:\n",
    "            if idx not in select_lab:\n",
    "                select_lab[idx] = []\n",
    "            r1 = [row[3]]\n",
    "            r1.extend(row[4:23])\n",
    "            select_lab[idx].append(r1)\n",
    "\n",
    "to_be_delete = [] # keys to be deleted\n",
    "count = 0\n",
    "max_row = 1900 # typically consider first 30 hours and vital is sample every minute\n",
    "for i in select_lab:\n",
    "    table = np.array(select_lab[i][:max_row])\n",
    "    if len(table) <= 1:\n",
    "        to_be_delete.append(i) # delete tables only have one time step\n",
    "        continue\n",
    "    if no_data(table):\n",
    "        to_be_delete.append(i) # delete tables that at least one attribute has no value at all time\n",
    "        continue\n",
    "    select_lab[i] = impute_table(table)\n",
    "    #print('Table: '+str(count))\n",
    "    count += 1\n",
    "    if count % 100 == 0:\n",
    "        print('Table: '+str(count))\n",
    "        \n",
    "for i in to_be_delete:\n",
    "    del select_lab[i]\n",
    "print(len(select_lab))\n",
    "file = open('./selected_lab.json', 'w')\n",
    "#select_lab = reformat(select_lab)\n",
    "json.dump(select_lab, file)\n",
    "################--IMPORTANT--#################\n",
    "## mnually open the file and scroll dowm to the end to see if the file format is correct.\n",
    "## Error can occur due to some unknown bug. Delete the incomplete data if neccessary and the total\n",
    "## number of tables should remain the same.\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data for training and testing\n",
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from bisect import bisect_right\n",
    "from bisect import bisect_left\n",
    "\n",
    "def read_json(path):\n",
    "    file = open(path)\n",
    "    data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def str2date(string):\n",
    "    return datetime.strptime(string, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "def read_duration(path, dataset='ventilation'):\n",
    "    # path = csv file of duration\n",
    "    data = {}\n",
    "    with open(path, newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        header = next(reader, None)\n",
    "        if dataset == 'ventilation':\n",
    "            for row in reader:\n",
    "                idx = row[0]\n",
    "                data[idx] = [row[2], float(row[4])] # start time as datetime object\n",
    "            return data # {icu:[starttime, hours]}\n",
    "        elif dataset == 'vassopressor':\n",
    "            for row in reader:\n",
    "                idx = row[0]\n",
    "                if idx not in data:\n",
    "                    data[idx] = [row[2], row[3]]\n",
    "                else:\n",
    "                    data[idx].append(row[2])\n",
    "                    data[idx].append(row[3])\n",
    "            return data # {icu:[stime1, etime1, stime2, etime2, ...]}\n",
    "        else:\n",
    "            raise Exception('Unknown dataset')\n",
    "\n",
    "def is_match(idx, tables):\n",
    "    # check if idx is in all tables\n",
    "    for i in tables:\n",
    "        if idx not in i:\n",
    "            return 0\n",
    "    return 1\n",
    "\n",
    "def read_classification(path):\n",
    "    data = {}\n",
    "    with open(path, newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        header = next(reader, None)\n",
    "        for row in reader:\n",
    "            idx = row[0]\n",
    "            if idx not in data:\n",
    "                data[idx] = []\n",
    "            r1 = [row[1]]\n",
    "            r1.extend(row[2:4])\n",
    "            data[idx].append(r1)\n",
    "    return data\n",
    "\n",
    "def get_indexed(table, icu):\n",
    "    # table = {icu:[time1, x1, x2,...],...}\n",
    "    # return selected table as a list of lists and time string is converted to datetime obj\n",
    "\n",
    "    t = np.array(table[icu])\n",
    "    data = []\n",
    "    for i in t:\n",
    "        time = datetime.strptime(i[0], '%Y-%m-%d %H:%M:%S').timestamp() # unit: second\n",
    "        r = [time]\n",
    "        for j in i[1:]:\n",
    "            r.append(float(j))\n",
    "        data.append(r)\n",
    "    return np.array(data)\n",
    "\n",
    "\n",
    "def get_weights(start, step, end):\n",
    "    # start >= step >= end\n",
    "    # w1: weight of start, w2: weight of end\n",
    "    if start == step and step == end:\n",
    "        return 0.5, 0.5\n",
    "    elif start == step:\n",
    "        return 1.0, 0.0\n",
    "    elif step == end:\n",
    "        return 0.0, 1.0\n",
    "    d1_reci = 1 / (step - start)\n",
    "    d2_reci = 1 / (end - step)\n",
    "    total = d1_reci + d2_reci\n",
    "    w1 = d1_reci / total\n",
    "    w2 = d2_reci / total\n",
    "    return w1, w2\n",
    "\n",
    "def extract(duration, select_lab, selected_vital, icu, total_duration, treatment_inter, dataset, classification=None):\n",
    "    # extract covariate and treatment given an icuid\n",
    "    # output format: {'x': [], 'y':[], 'T':[]}\n",
    "    try:\n",
    "        starttime = str2date(duration[icu][0]).timestamp()\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "    lab = get_indexed(select_lab, icu)\n",
    "    vital = get_indexed(selected_vital, icu)\n",
    "    y = []\n",
    "    x = []\n",
    "    T = []\n",
    "\n",
    "    \n",
    "    if dataset.lower() == 'ventilation':\n",
    "        classi = get_indexed(classification, icu)\n",
    "        length = [len(lab), len(vital), len(classi)]\n",
    "        for i in range(0, total_duration, treatment_inter):\n",
    "            time_setp = starttime + i*3600\n",
    "            #classi_idx = bisect_right(classi[:, 0], time_setp)\n",
    "            bisect_num = [bisect_right(lab[:,0], time_setp), bisect_right(vital[:, 0], time_setp), bisect_right(classi[:, 0], time_setp)]\n",
    "            if 0 in bisect_num:\n",
    "                continue\n",
    "            #outcome_time = time_setp + treatment_inter * 3600 / 2 # half hour between T and Y\n",
    "            if  np.any(np.diff(np.dstack((bisect_num,length)))==0):\n",
    "                break\n",
    "                \n",
    "                \n",
    "            ## the treatment time step is 5 min after x_time, the treatment is indicated by the classification \n",
    "            ## to the left of the t_time.\n",
    "            t_time = time_setp + 300 # 5 min = 300 sec\n",
    "            t_idx = bisect_right(classi[:, 0], t_time)\n",
    "            if t_idx == length[2] - 1:\n",
    "                break\n",
    "            mchv = classi[t_idx-1][1]  # mechanical ventilator\n",
    "            oxyth = classi[t_idx-1][2]  # oxygentherapy\n",
    "\n",
    "            if oxyth == 1.0:\n",
    "                break\n",
    "            \n",
    "            \n",
    "            x_idx = bisect_right(vital[:, 0], time_setp)\n",
    "            if x_idx == length[1] - 1:\n",
    "                break # out of range\n",
    "            w1, w2 = get_weights(vital[x_idx-1][0], time_setp, vital[x_idx][0])\n",
    "            x_temp = (vital[x_idx - 1][1:] * w1 + vital[x_idx][1:] * w2).tolist() # interpolate vital\n",
    "\n",
    "            x_idx = bisect_right(lab[:, 0], time_setp)\n",
    "            if x_idx == length[0] - 1:\n",
    "                break # out of range\n",
    "            w1, w2 = get_weights(lab[x_idx-1][0], time_setp, lab[x_idx][0])\n",
    "            x_temp1 = (lab[x_idx - 1][1:] * w1 + lab[x_idx][1:] * w2).tolist() # interpolate lab\n",
    "            x_temp.extend(x_temp1)\n",
    "            \n",
    "            \n",
    "            y_timestep = t_time + 300 # 5 min after the treatment\n",
    "            y_idx = bisect_right(vital[:, 0], y_timestep)\n",
    "            if y_idx == length[1] - 1:\n",
    "                break\n",
    "            w1, w2 = get_weights(vital[y_idx-1][0], y_timestep, vital[y_idx][0])\n",
    "            y.append((vital[y_idx-1][-1] * w1 + vital[y_idx][-1] * w2) / 2)\n",
    "            \n",
    "            x.append(x_temp)\n",
    "            T.append(mchv)\n",
    "            \n",
    "        return 0 if x == [] or y == [] or T == [] else {'x': x, 'y':y, 'T':T} \n",
    "            \n",
    "    \n",
    "            \n",
    "    elif dataset.lower() == 'vasopressor':\n",
    "        length = [len(lab), len(vital)]\n",
    "        treatment_period = []\n",
    "        for i in duration[icu]:\n",
    "            treatment_period.append(str2date(i).timestamp())\n",
    "        for i in range(0, total_duration, treatment_inter):\n",
    "            time_setp = starttime + i*3600\n",
    "            bisect_num = [bisect_right(lab[:,0], time_setp), bisect_right(vital[:, 0], time_setp)]\n",
    "            if 0 in bisect_num:\n",
    "                continue\n",
    "            outcome_time = time_setp + treatment_inter * 3600 / 2 # half hour between T and Y\n",
    "            if bisect_right(vital[:, 0], outcome_time) == length[1] or np.any(np.diff(np.dstack((bisect_num,length)))==0):\n",
    "                break\n",
    "                \n",
    "            t_idx = bisect_right(treatment_period, time_setp)\n",
    "            x_time = treatment_period[t_idx - 1]\n",
    "            x_idx = bisect_right(vital[:, 0], x_time)\n",
    "            if x_idx == length[1] - 1:\n",
    "                break # out of range\n",
    "            w1, w2 = get_weights(vital[x_idx-1][0], x_time, vital[x_idx][0])\n",
    "            x_temp = (vital[x_idx - 1][1:] * w1 + vital[x_idx][1:] * w2).tolist() # interpolate vital\n",
    "            del x_temp[-6] # sysbp\n",
    "            del x_temp[-5] # diabp\n",
    "            del x_temp[-4] # meanbp\n",
    "            \n",
    "            x_idx = bisect_right(lab[:, 0], x_time)\n",
    "            if x_idx == length[0] - 1:\n",
    "                break # out of range\n",
    "            w1, w2 = get_weights(lab[x_idx-1][0], x_time, lab[x_idx][0])\n",
    "            x_temp1 = (lab[x_idx - 1][1:] * w1 + lab[x_idx][1:] * w2).tolist() # interpolate lab\n",
    "            x_temp.extend(x_temp1)\n",
    "            \n",
    "            y_idx = bisect_right(vital[:, 0], outcome_time)\n",
    "            if y_idx == length[1] - 1:\n",
    "                break\n",
    "            w1, w2 = get_weights(vital[y_idx-1][0], outcome_time, vital[y_idx][0])\n",
    "            y.append((vital[y_idx-1][-1] * w1 + vital[y_idx][-1] * w2) / 2)\n",
    "            \n",
    "            if  t_idx % 2 == 0:\n",
    "                T.append(0) # even = no treatment, odd = treatment\n",
    "            else:\n",
    "                T.append(1)\n",
    "            x.append(x_temp)\n",
    "        return 0 if x == [] or y == [] or T == [] else {'x': x, 'y':y, 'T':T}\n",
    "    else:\n",
    "        raise Exception('Error: unknown dataset')\n",
    "        exit(0)\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'ventilation' # ventilation or vasopressor\n",
    "total_duration = 30 # hours\n",
    "treatment_inter = 1 # hour\n",
    "select_lab = './selected_lab.json'\n",
    "selected_vital = './selected_vital.json'\n",
    "static = './static_features.json'\n",
    "\n",
    "# read in data\n",
    "static_features = read_json(static)\n",
    "select_lab = read_json(select_lab) # {icu:[[time1, x1,x2,...],...}\n",
    "selected_vital = read_json(selected_vital) # {icu:[[time1, x1,x2,...],...} NO glucose !!! as that has been contained in lab\n",
    "if dataset.lower() == 'ventilation':\n",
    "    duration = read_duration('./ventilation_durations.csv')\n",
    "    classification = read_classification('./ventilation_classification.csv') # {icu:[[time, vent, oxy],...]}\n",
    "    \n",
    "elif dataset.lower() == 'vassopressor':\n",
    "    duration = read_duration('./vasopressor_durations.csv', dataset=dataset)\n",
    "    classification = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    \n",
    "dataset = 'ventilation' # ventilation or vassopressor\n",
    "total_duration = 30 # hours\n",
    "treatment_inter = 1 # hour\n",
    "select_lab = './selected_lab.json'\n",
    "selected_vital = './selected_vital.json'\n",
    "static = './static_features.json'\n",
    "\n",
    "# read in data\n",
    "static_features = read_json(static)\n",
    "select_lab = read_json(select_lab) # {icu:[[time1, x1,x2,...],...}\n",
    "selected_vital = read_json(selected_vital) # {icu:[[time1, x1,x2,...],...}\n",
    "'''\n",
    "    \n",
    "\n",
    "                             \n",
    "data = {}\n",
    "for i in static_features:\n",
    "    w = static_features[i]['weight']\n",
    "    dynamic = {}\n",
    "    for idx in w:\n",
    "        icu = idx[2:8] # length of id = 6\n",
    "        if is_match(icu, [select_lab, selected_vital]):\n",
    "            match = 1\n",
    "            weight = w[idx]\n",
    "            bmi = static_features[i]['bmi'][idx]\n",
    "            extract_val = extract(duration, select_lab, selected_vital, icu, total_duration, treatment_inter, dataset, classification=classification)\n",
    "            if extract_val:\n",
    "                dynamic[icu] = extract_val\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    if dynamic != {}:\n",
    "        static = []\n",
    "        attribute = static_features[i]\n",
    "        for j in ['age', 'sex', 'race', \"metastatic_cancer\", \"diabetes\", \"height\"]:\n",
    "            static.append(attribute[j])\n",
    "        data[i] = {'static': static, 'dynamic': dynamic}\n",
    "\n",
    "filename = './' + dataset + '_' + 'duration_' + str(total_duration) + '.json'\n",
    "file = open(filename, 'w')\n",
    "json.dump(data, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'200025'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(duration.keys())[2\n",
    "                     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2055"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
